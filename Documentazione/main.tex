\documentclass{article}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[letterpaper,top=3cm,bottom=3cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{enumitem}
\usepackage{subfig}
\usepackage[italian]{babel}
\begin{document}

\begin{titlepage}
    \begin{center}

        \textbf{\LARGE Università degli studi di salerno}

        \vspace{0.5cm}
        
        \includegraphics[width=0.5\textwidth]{unisa.png} 
        
        \vspace{0.3cm}
                
        \large Dipartimento di Informatica
        
        \vspace{3cm}
        
        \Huge \textbf{Sapore DiVino}
        
        \vspace{0.2cm}
        
        \large Progetto realizzato per il corso di \textit {Fondamenti di Intelligenza Artificiale}
        
        \vspace{3.0cm}
        
        \large \textbf{Progettista:} Fabio Sessa \\
        \large \textbf{Matricola:} 0512114634 \\
        \vspace{1.6cm}
        2023/2024
        
        \vspace{2cm}
    \end{center}
        \newpage
        \tableofcontents

        \newpage
        \section{Introduzione}
            L'universo del vino è un affascinante viaggio sensoriale che coinvolge tutti i nostri sensi, dalla vista al gusto, fino all'olfatto. Gli appassionati di vino apprezzano non solo la bevanda in sé, ma anche la complessità e la raffinatezza che si celano dietro ogni bottiglia. \\
            Per la realizzazione di questo progetto presente nella mia \href{https://github.com/bafiuss/SaporeDiVino.git}{repository GitHub}, sono presenti tutti i file relativi alla documentazione, presentazione e codice. 

        
        \subsection{Obiettivi}
            Durante realizzazione di questo progetto per il corso Fondamenti di Intelligenza Artificiale, mi sono cimentato in un problema comune di classificazione per quanto riguarda il Machine Learning; riguardo questo campo ho sempre avuto un interesse particolare ma prima di questa esperienza non né ho mai avuto un approccio effettivo. \\
            Le tematiche che andremo a toccare e gli obiettivi principali sono:
             \begin{itemize}
                \item analisi dettagliata di un \href{https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009}{dataset di vini rossi};
                \item l'identificazione di feature associate ai vini;
                \item l'implementazione di un modello di apprendimento in grado di classificare in modo affidabile la qualità di vini sufficienti e insufficienti.
            \end{itemize}
            
        \subsection{Specifica PEAS}
        \begin{itemize}
            \item \textbf{Performance}, ovvero le misure di prestazione adottate per valutare l’operato di un agente. Nel mio caso precision, recall, accuracy e F-score;
            \item \textbf{Environment}, ovvero gli elementi che formano l’ambiente. Nel mio caso sarà costituito dall'elenco dei vini rossi;
            \item \textbf{Actuators}, ovvero gli attuatori disponibili all’agente per intraprendere le azioni. Nel mio caso sarà l'utilizzo di algoritmi di classificazione;
            \item \textbf{Sensors}, ovvero i sensori attraverso i quali l'agente riceve gli input percettivi. Nel mio caso l'agente va ad acquisire i dati utili per classificare la qualità di un vino.
        \end{itemize}

        \newpage
        \subsection{Caratteristiche dell'ambiente}
        L'ambiente è:
        \begin{itemize}
            \item \textbf{Single-agent}.
            \item \textbf{Parzialmente osservabile}: non si ha accesso a tutte le informazioni complete relative ai vini;
            \item \textbf{Stocastico}: le qualità dei vini possono essere influenzate da fattori  difficilmente prevedibili o che presentano una certa variabilità;
            \item \textbf{Sequenziale}:  le predizioni passate sulla risposta al trattamento possono
            fornire un contesto importante per valutare l’efficacia delle qualità successive.
            \item \textbf{Dinamico}: la qualità può variare di vino in vino;
            \item \textbf{Discreto}: le variabili assumono valori in un limitato intervallo; alcune, invece, assumono valori distinti e separati.
        \end{itemize}

        \subsection{Analisi del problema}
        L'intero progetto affronta, dunque, quello che un problema di \textbf{apprendimento supervisionato} basato sulla costruzione di un modello di Machine Learning. 
        Inoltre, la classificazione che andremo ad utilizzare sarà di tipo \textbf{binario}, dato che può assumere valori 0 e 1 (1 se il vino ha una qualità almeno sufficiente, 0 se il vino ha una qualità insufficiente) \\
        Le tecnologie e gli strumenti che ho utilizzato sono i seguenti:
        \begin{itemize}
            \item \textbf{Visual Studio Code} come IDE;
            \item \textbf{Python} come linguaggio di programmazione;
            \item \textbf{GitHub} per il versionamento;
            \item \textbf{JupyterNotebook} all’interno dell’IDE;
            \item \textbf{Overleaf} per la scrittura della documentazione;
            \item \textbf{Canva} per la realizzazione della presentazione.
        \end{itemize}

        \newpage
        \section{Data Understanding}
        La fase di Data Understanding implica un esame più attento dei dati disponibili per il data mining. Questo passaggio è di fondamentale importanza per evitare problemi imprevisti durante la fase successiva di Data Preparation, che è in genere la parte più lunga di un progetto. \\
        Inoltre questa fase è composta da:
        \begin{itemize}
            \item \textbf{Data Collection};
            \item \textbf{Data Description};
            \item \textbf{Data Quality}.
        \end{itemize}

         \subsection{Data Collection}
         In linea generale, la fase di Data Collection è il processo di raccolta, misurazione e analisi delle informazioni provenienti da innumerevoli fonti diverse. Dopo varie ricerche online del giusto dataset, ho deciso di scegliere un dataset presente su Kaggle,  una piattaforma online dedicata alle competizioni di data science, Machine Learning e analisi dei dati. \\Il riferimento al dataset lo si può trovare al seguente \href{https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009}{link}.

         \subsection{Data Description}
         Il dataset scelto presenta un elenco di vini e per gli appassionati, si tratta di vini rossi provenienti dal Portogallo. Possiamo trovare la bellezza di ben 1599 righe e 12 colonne. L'ultima colonna, ovvero 'quality', è quella che utilizzeremo per stabilire se la qualità di un vino è almeno sufficiente (qualità del vino \( > \)=6) oppure insufficiente (qualità del vino \( < \)6). \\
         Non essendo un esperto ed appassionato di chimica, ho dovuto studiare più nel dettaglio quelle che sono le caratteristiche che formano il dataset. Di seguito vi è una descrizione generale e sintetica delle caratteristiche:
         \begin{enumerate}
            \item \textbf{Fixed acidity}: si riferisce alla quantità di acidi presenti nel vino;
            \item \textbf{Volatile acidity}: si riferisce alla presenza di acidi volatili, ovvero composti chimici acidi che possono evaporare facilmente in forma di gas;
            \item \textbf{Citric acid}: elemento che può contribuire al profilo di acidità totale del vino;
            \item \textbf{Residual sugar}: si riferisce agli zuccheri lasciati non fermentati in un vino finito;
            \item \textbf{Chlorides}: quantità di sale nel vino;
            \item \textbf{Free sulfur dioxide}: sono i sulfuri disponibili a reagire e quindi presentano proprietà sia germicide che antiossidanti;
            \item \textbf{Total sulfur dioxide}: rappresenta la somma delle quantità di anidride solforosa libera e combinata presenti nel vino;
            \item \textbf{Density}: si riferisce alla quantità di materia presente in una determinata quantità di liquido;
            \item \textbf{pH}: descrive quanto è acido o basico un vino su una scala da 0 (molto acido) a 14 (molto basico);
            \item \textbf{Sulphates}: si riferiscono all'anidride solforosa (SO2), un composto chimico usato come conservante;
            \item \textbf{Alcohol}: percentuale di alcol del vino;
            \item \textbf{Quality}: variabile di output (sulla base dei dati sensoriali, punteggio compreso tra 3 e 8). 
         \end{enumerate}

        \newpage
        Un altro strumento molto utile per capire meglio la distribuzione dei dati è l'uso dei grafici, più in particolare degli istogrammi. Di seguito vi è una rappresentazione grafica riguardante le la quantità di alcohol presente nei vini suddivisi per qualità

        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.5\linewidth]{barPlot-alcohol.png}
            \caption{ quantità di alcohol nei vini suddivisi per qualità}
            \label{fig:enter-label}
        \end{figure}

        Come possiamo notare dal grafico, la qunatità di alcohol nei vini aumenta con l'aumentare della qualità di quest'ultimi.
        
        Il grafico seguente, invece, rappresenta le frequenze di vini di ogni qualità
        
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.5\linewidth]{countPlot-quality.png}
            \caption{ frequenze delle qualità}
            \label{fig:enter-label}
        \end{figure}

        Salta subito all'occhio che il grafico è meno distribuito rispetto al precedente, ma possiamo trarre alcune conclusioni, come ad esempio la moda della qualità che è rappresentata dal valore 5; inoltre la quantità di vini con qualità ottima/eccellente è molto scarsa.

        \newpage
        \subsection{Data Quality}
        In questa fase vado ad analizzare la qualità dei miei dati.
        L'obiettivo primario, ricordiamo, è la corretta classificazione della qualità di un vino e classificarla come almeno sufficiente (qualità \( >\)=6) o come insufficiente (qualità \( <\)6). Non mi resta altro che suddividere la qualità in queste due categorie e con l'aiuto del grafico possiamo studiare al meglio la situazione

        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.5\linewidth]{pie-quality.png}
            \caption{  percentuali di frequenza delle classi}
            \label{fig:enter-label}
        \end{figure}

        Dal grafico a torta possiamo notare che i vini con una qualità almeno sufficiente sono molti di più rispetto ai vini con una qualità insufficiente.        
        Inoltre, dobbiamo gestire anche il problema dello sbilanciamento, ma questa tematica sarà affrontata più avanti nella fase del Data Balancing.

        \section{Data Preparation}
        La fase di Data Preparation ha lo scopo di eseguire una serie di attività volte a raccogliere, pulire, trasformare e organizzare i dati in modo che siano pronti per l'analisi o per l'addestramento di modelli di machine learning.
        Tale fase è suddivisa in diverse fasi, eseguite in modo cronologico:
        \begin{itemize}
            \item Data Cleaning
            \item Feature Scaling
            \item Feature Selection
            \item Data Balancing
        \end{itemize}

        \subsection{Data Cleaning}
        La fase di Data Cleaning  è progettata per identificare e correggere gli errori, le inconsistenze e le irregolarità nei dati raccolti. Alcuni esempi possono essere la presenza di dati mancanti in alcune righe, la presenza di intere colonne con valore nullo oppure la presenza di duplicati all'interno del dataset. Nel mio caso, non avendo valori nulli, ho dovuto affrontare solo il problema dei duplicati (ben 240) che non ho esitato a rimuovere, dato che potrebbero creare problemi nella classificazione binaria. 

        \newpage
        \subsection{Feature Scaling}
        La fase di Feature Scaling consiste nel trasformare le variabili del dataset in modo che siano tutte su una scala comune. Il motivo principale dietro tale fase è che molte tecniche di Machine Learning possono essere influenzate negativamente da differenze nelle scale delle variabili. \\Le due tecniche che abbiamo studiato sono: min-max normalization e z-score normalization; tra le due ho optato per la tecnica del \textbf{min-max normalization}, dove l'obiettivo di questa tecnica è trasformare le variabili in modo che abbiano valori compresi tra un certo intervallo, di solito tra 0 e 1. \\
         Prima di proseguire con la normalizzazione, mi sono adoperato ad effettuare la divisione del dataset e affrontare il problema del data leakage (fuga di dati). La divisione del dataset è avvenuta in due gruppi: il 70\% del è dedicato all'addestramento (\textbf{training set}) e il 30\% è dedicato al testing (\textbf{test set}).
        Dopo aver normalizzato, posso passare alla fase successiva, ossia la Feature Selection.

        \subsection{Feature Selection}
        Tale fase è un processo che coinvolge la scelta delle variabili (o caratteristiche) più rilevanti da utilizzare per costruire un modello predittivo o analizzare i dati. In generale, le "feature" si riferiscono alle variabili o attributi che vengono utilizzati per descrivere gli esempi nei dati. \\
        Per ottenere una panoramica generale delle correlazioni tra le varie caratteristiche, mi sono aiutato con quella che viene chiamata \textbf{matrice di correlazione}: una matrice quadrata in cui ogni cella rappresenta la correlazione tra due variabili. Di seguito una guida per leggere al meglio una matrice di correlaizione:
        
        \begin{itemize}
            \item la diagonale principale della matrice contiene sempre valori di correlazione 1, poiché una variabile è sempre perfettamente correlata con se stessa;
            \item le celle più scure o più chiare indicano correlazioni più forti o più deboli, rispettivamente.
            \item le variabili sono fortemente correlate tra loro se hanno valori vicini a 1 o -1, mentre hanno una bassa correlazione se hanno valori vicini a 0.
        \end{itemize}

        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{correlation-matrix.png}
            \caption{  matrice delle correlazioni}
            \label{fig:enter-label}
        \end{figure}

        \newpage
        La matrice di correlazione appena calcolata presenta il problema di \textbf{multicollinearità}, ovvero in cui due o più variabili indipendenti sono fortemente correlate tra loro; infatti:
        \begin{itemize}
            \item \textbf{free-sulfur-dioxide} e \textbf{total-sulfur-dioxide} sono ben correlate positivamente (0.67);
            \item\textbf{pH} e \textbf{fixed-acidity} sono altamente correlate negativamente (-0.69).
        \end{itemize}

        \subsection{Data Balancing}
        L'obiettivo del Data Balancing è affrontare situazioni in cui le classi di un insieme di dati non sono rappresentate in modo uniforme, cioè alcune classi possono essere sovrarappresentate rispetto ad altre.\\
        Come enunciato in precedenza, il mio dataset presenta una classe maggioritaria di vini con qualità almeno sufficiente rispetto a vini con qualità insufficiente. Le tecinche che ho studiato durante il corso sono:
        \begin{itemize}
            \item la tecnica dell'\textbf{under-sampling}: eliminare casualmente le istanze della classe di maggioranza;
            \item la tecnica dell'\textbf{over-sampling}: aggiungere casualmente le istanze della classe di minoranza.
        \end{itemize}
        Entrambe le tecniche vanno usate nel giusto modo e trattate con particolare attenzione.\\ Per bilanciare il dataset e per evitare di andare ad effettuare duplicazioni che potrebbero causare overfitting (quando un modello di Machine Learning si adatta troppo bene ai dati di addestramento) con l'utilizzo dell'over-sampling, ho preferito utilizzare la tecnica dell'\textbf{under-sampling}. \\ La rimozione delle istanze della classe maggioritaria è stata effettuata tramite \textit{RandomUndersampler}, uno strumento contenuto nella libreria sklearn.
        \section{Data Modeling}
        Dopo aver effettuato le varie operazioni riguardanti la Data Preparation, possiamo affrontare quella che è la fase del Data Modeling. Tale fase, infatti, comprende diverse attività cruciali che si sulla rappresentazione dei dati in modo che possano essere utilizzati efficacemente dal modello di Machine Learning.

        \subsection{Scelta dei classificatori}
        I classificatori in Machine Learning sono algoritmi o modelli che vengono addestrati per assegnare etichette ai dati sulla base delle informazioni apprese da dati precedentemente etichettati durante la fase di addestramento. \\
        Nel mio caso, l'intero progetto è strutturato su un problema di classificazione binaria, dove la variabile target può assumere può assumere il valore 0 se la qualità è insufficiente, oppure il valore 1 se la qualità è almeno sufficiente. Tra i classificatori studiati durante il corso, possiamo trovare l'algoritmo di \textbf{Naive Bayes} (e relative varianti) e i \textbf{decision tree} (alberi decisionali). Navigando online se né possono trovare a migliaia, tra cui il Random Forest, K-Nearest Neighbors etc. \\
        La mia scelta di implementazione dei classificatori è ricaduta su:
        \begin{itemize}
            \item Naive Bayes (con relative varianti);
            \item Decision Tree;
            \item Random Forest.
        \end{itemize}

        \newpage
        \subsubsection{Naive Bayes (definizione)}
        L'algoritmo di Naive Bayes è un tipo di algoritmo di apprendimento automatico supervisionato basato sul teorema di Bayes, che sfrutta la probabilità condizionale. L'approccio "naive" (ingenuo) deriva dal fatto che l'algoritmo assume l'indipendenza condizionale tra ogni coppia di caratteristiche, anche se questo potrebbe non essere sempre realistico nella pratica.
        Inoltre all'algoritmo di Naive Bayes sono associate diverse varianti, che però daremo la definizione del loro comportamento nella fase di addestramento; per adesso mi limito solo ad elencarle:
        \begin{itemize}
            \item Gaussian Naive Bayes;
            \item Multinomial Naive Bayes;
            \item Bernoulli Naive Bayes.
        \end{itemize}

        \subsubsection{Decision Tree (definizione)}
        Gli alberi decisionali sono modelli utilizzati per compiti di classificazione (anche di regressione). Sono costruiti a partire da un set di dati di addestramento, e il loro obiettivo è quello di apprendere regole decisionali basate sugli attributi dei dati.
        Un albero decisionale è costituito da nodi e archi. Ogni nodo rappresenta una decisione basata su un attributo specifico, mentre gli archi collegano i nodi e rappresentano le possibili scelte o risultati delle decisioni. Il nodo iniziale, chiamato nodo radice, rappresenta la decisione iniziale basata sull'attributo più significativo, attraverso misure come l’entropia
        o l’information-gain. Gli altri nodi, noti come nodi interni, rappresentano decisioni intermedie, mentre i nodi foglia rappresentano le etichette di classificazione.

        \subsubsection{Random Forest (definizione)}
         L'algoritmo Random Forest combina l’output di più strutture
         (Ensemble Learning) ad albero decisionale per raggiungere un unico risultato.  Random Forest combina i risultati di più alberi decisionali fornendo,
         generalmente, risultati più accurati di un singolo Decision Tree.
         
        \subsection{Addestramento}
         In questa sezione procedo ad addestrare il modello in base agli algoritmi scelti in precedenza. Nel mio caso, come già detto, procedo prima all’addestramento usando Naive Bayes, per poi fare lo stesso con Decision Tree e infine Random Forest. Dopodiché valuterò le
         prestazioni ottenute e le metterò a confronto. Tutto ciò mi consentirà di capire quale algoritmo si adatta meglio al problema, e va di conseguenza a fare delle predizioni migliori.
        
        \newpage
        \subsubsection{Gaussian Naive Bayes}
         L'algoritmo Gaussian Naive Bayes è una delle varianti dell'algoritmo di Naive Bayes ed è particolarmente utile quando si lavora con dati che possono essere descritti utilizzando distribuzioni gaussiane (normali). Andiamo a studiare più nel dettaglio il comportamento di questo algoritmo:

         \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{confusion_matrix-GNB.png}
            \caption{  matrice di confusione Gaussian Naive Bayes}
            \label{fig:enter-label}
        \end{figure}
        
        \subsubsection{Multinomial Naive Bayes}
        L'algoritmo Multinomial Naive Bayes è la seconda variante che andremo a studiare dell'algoritmo di Naive Bayes ed è particolarmente utile per problemi di classificazione di testi.\\ Notiamo la matrice di confusione disegnata:
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{confusion_matrix-MNB.png}
            \caption{  matrice di confusione Multinomial Naive Bayes}
            \label{fig:enter-label}
        \end{figure}
        
        \subsubsection{Bernoulli Naive Bayes}
        Infine, l'ultima variante che andremo a studiare è quella relativa all'algoritmo Bernoulli Naive Bayes. Tale algoritmo èè particolarmente utile per dati binari.
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{confusion_matrix-BNB.png}
            \caption{  matrice di confusione Bernoulli Naive Bayes}
            \label{fig:enter-label}
        \end{figure}

        \subsubsection{Confronto tra GNB - MNB - BNB}
        Dopo aver studiato il comportamento di ogni singola variante dell'algoritmo di Naive Bayes, passiamo a confrontare i risultati ottenuti e fare le prime deduzioni. Per fare ciò ho bisogno di metriche specifiche, chiamate \textbf{metriche di valutazione}. Le principaili e quelle più famose sono \textbf{precision}, \textbf{recall} e \textbf{accuracy}; ma ho voluto studiare il comportamento anche della metrica \textbf{F-score}:
        \begin{itemize}
            \item \textbf{Precision}: misura la proporzione di casi positivi effettivamente positivi tra tutte le predizioni positive fatte dal modello;
            \item \textbf{Recall}: misura la capacit`a del modello di identificare correttamente i casi positivi rispetto al totale dei casi positivi reali;
            \item \textbf{Accuracy}: misura la proporzione complessiva di predizioni corrette fatte dal modello rispetto al totale delle predizioni;
            \item \textbf{F-score}: misura che viene calcolata tramite la media armonica di precision e recall.
        \end{itemize}
        \newpage
        \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \textbf{Classificatore} & \textbf{Precision} & \textbf{Recall} & \textbf{Accuracy}& \textbf{F-score}\\ \hline
            Gaussian NB & 0.793103 & 0.738532 & 0.757353 & 0.764846\\ \hline
            Multinomial NB & 0.784615 & 0.701835 & 0.737745 & 0.740920\\ \hline
            Bernoulli NB & 0.541779 & 0.922018 & 0.541667 & 0.682513\\ \hline
        \end{tabular}
        \end{center}

        Come possiamo notare dalla tabella, i valori delle metriche non sono altissimi: in particolare notiamo che l'algoritmo Bernoulli Naive Bayes pecca sulla precision e sull'accuracy ma compensa con un valore di recall abbastanza alto; per quanto riguarda gli altri due algoritmi hanno risultati simili. Per scelta implementativa, l'obiettivo è quello di \textbf{massimizzare la metrica F-score} e l'algoritmo massimizza questa metrica è l'algoritmo di \textbf{Gaussian Naive Bayes} (0.764846). 

        \subsubsection{Decision Tree}
        Dopo aver dato la definizione in precedenza, cerchiamo di implementare l'algoritmo di Decision Tree, studiamo come si adatta ai dati e vediamo se otteniamo miglioramenti rispetto agli algoritmi di Naive Bayes

        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{confusion_matrix-DT.png}
            \caption{  matrice di confusione Decision Tree}
            \label{fig:enter-label}
        \end{figure}
        \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \textbf{Classificatore} & \textbf{Precision} & \textbf{Recall} & \textbf{Accuracy}& \textbf{F-score}\\ \hline
            Decision Tree & 0.704453 & 0.798165 & 0.713235 & 0.748387\\ \hline
        \end{tabular}
        \end{center}
        Rispetto alla recall del Gaussian Naive Bayes (0.764846) abbiamo avuto un \textbf{peggioramento dell'F-score} (0.748387) ma anche un miglioramento per quanto riguarda la precision (0.793103), accuracy (0.757353 ). Ma a noi interessa solo dell'F-score, quindi abbiamo avuto un peggioramento delle prestazioni
        \newpage
        \subsubsection{Random Forest}
        L'ultimo algoritmo che sono andato ad implementare è Random Forest. Vediamo come si comporta
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{confusion_matrix-RF.png}
            \caption{  matrice di confusione Random Forest}
            \label{fig:enter-label}
        \end{figure}
        \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \textbf{Classificatore} & \textbf{Precision} & \textbf{Recall} & \textbf{Accuracy}& \textbf{F-score}\\ \hline
            Decision Tree & 0.762332 & 0.779817 & 0.752451 & 0.770975\\ \hline
        \end{tabular}
        \end{center}
        In questo caso, abbiamo avuto un miglioramento della metrica F-score rispetto alla precedente del Gaussian Naive Bayes (0.764846)
        
        \newpage
        \section{Evaluation}
        Implementati tutti quelli che sono gli algoritmi per la classificazione scelti, facciamo una panoramica e mettiamoli tutti a confronto tramite l'uso di un istogramma.
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{comparison.png}
            \caption{  confronto delle metriche di ogni algoritmo implementato}
            \label{fig:enter-label}
        \end{figure}
        
        Possiamo notare che alcuni algoritmi (come MNB, GNB) operano davvero in modo molto simile; però, come già detto in precedenza, l'obiettivo è quello di massimizzare il valore della metrica F-score (quindi avere il miglior apporto precision-recall) e l'algoritmo che si adatta meglio al valore è quello del Random Forest (0.770975).
        Per avere più chiara la bontà del modello ho effettuato un’ulteriore valutazione attraverso la ROC
        AUC curve, che consente di visualizzare il trade-off tra Recall e specificità. In poche parole misura la
        capacità di identificare correttamente i casi negativi, ovvero quanto bene il modello riesce a distinguere
        tra messaggi vini di con qualità insufficiente o almeno sufficiente.
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.6\linewidth]{roc-auc-curve.png}
            \caption{  confronto delle metriche di ogni algoritmo implementato}
            \label{fig:enter-label}
        \end{figure}

        La linea diagonale rappresenta il risultato di una scelta casuale, quindi un
        qualunque modello utile deve essere al suo di sopra. Inoltre un buon modello
        deve posizionarsi in alto a sinistra, ovvero deve avere sensibilità elevata e basso
        tasso di falsi positivi, cio‘e il modello deve riuscire correttamente a predirre che
        un paziente ha il cancro al seno senza generare falsi positivi, ovvero predirre
        che un vino abbia una qualità almeno sufficiente, ma in realtà non lo ha.
        
        Ultima non meno
        importante la AUC (Area sotto la curva) che fornisce una misura generale delle
        prestazioni del modello, ad esempio un’area di 1.0 indica un modello perfetto,
        mentre un’area di 0.5 indica una scelta casuale. Il mio modello ha ottenuto
        un valore pari a 0.84, che è un ottimo risultato ma non eccellente. Quindi posso considerare la
        costruzione del modello e in generale dell’approccio completa.

        \section{Conclusioni}
        La realizzazione di questo progetto mi ha portato ad avere un primo approccio su un problema di Machine Learning. Posso dire che è stata un'esperienza che mi ha divertito e soprattutto appassionato nella ricerca di effettuare miglioramenti al modello. Che questo possa essere solo l'inizio di una strada interessante come quello dell'Intelligenza Artificiale!
        
\end{titlepage}
\end{document}
